# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oAh8WwijzsSfTML5-B8YU3wewN8_gzpi
"""

!pip install gradio

import gradio as gr
from transformers import AutoTokenizer, AutoModelForTokenClassification

# Load the NER model and tokenizer
model_name = "dslim/bert-base-NER"  # Replace with your chosen model
model = AutoModelForTokenClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

import torch
# Define the function to process the input text and labels
def process_text(text, labels):
    # Tokenize the text and labels
    inputs = tokenizer(text, return_tensors="pt", is_split_into_words=True)
    labels = [tokenizer.encode(label)[0] for label in labels]
    inputs["labels"] = torch.tensor(labels)

    # Make predictions within the function
    with torch.no_grad():
        outputs = model(**inputs)
        predictions = torch.argmax(outputs.logits, dim=-1)

    # Extract named entities
    label_map = tokenizer.vocab # Access the vocab directly
    predicted_entities = [label_map[pred.item()] for pred in predictions[0]]

    # Create a dictionary of extracted information
    extracted_info = {}
    for i, entity in enumerate(predicted_entities):
        if entity != "O":  # Filter out "O" labels (non-entity)
            start_index = inputs.input_ids.indices[i]
            end_index = inputs.input_ids.indices[i + 1]
            extracted_info[entity] = text[start_index:end_index]

    return extracted_info

# Create Gradio components
text_input = gr.Textbox(label="Enter your text")
label_input = gr.Textbox(label="Enter labels (comma-separated)")
file_input = gr.File(label="Upload a file")
output_text = gr.Textbox(label="Extracted information")

# Create the Gradio interface
iface = gr.Interface(
    fn=process_text,
    inputs=[text_input, label_input, file_input],
    outputs=output_text,
    title="NER with Custom Labels"
)

# Launch the interface
iface.launch()